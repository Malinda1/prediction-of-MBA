{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b5feccd-4c45-426f-8452-de46b2876d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bca55cc6-3ce8-4c3b-a0a3-4d7cd02583c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ebb61a2-820d-42e7-b51f-db75fc7e6b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load and prepare your data\n",
    "\n",
    "def load_data():\n",
    "\n",
    "  data = pd.read_csv(f'feature_engineered_dataset.csv')\n",
    "\n",
    "  X = data.drop(columns = ['remainder__Decided to Pursue MBA?'])\n",
    "  y = data['remainder__Decided to Pursue MBA?']\n",
    "\n",
    "  print(\"Please replace the load_data function with your actual data loading code\")\n",
    "  return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6cb16598-9bd1-4b3a-bd9c-a9fd9f604e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a model with given hyperparameters\n",
    "\n",
    "def create_model(params):\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # Input layer\n",
    "    model.add(Dense(\n",
    "        units = params['units_1'],\n",
    "        activation = params['activation'],\n",
    "        kernel_regularizer = tf.keras.regularizers.l1_l2(l1 = params['l1'], l2 = params['l2']),\n",
    "        input_dim = X_train.shape[1]\n",
    "    ))\n",
    "\n",
    "    # Add dropout after first layer\n",
    "    model.add(Dropout(params['dropout_1']))\n",
    "\n",
    "    # Hidden layer\n",
    "    for i in range(params['n_layers']):\n",
    "        model.add(Dense(\n",
    "            units = params[f'units_{i+2}'],\n",
    "            activation = params['activation'],\n",
    "            kernel_regularizer = tf.keras.regularizers.l1_l2(l1 = params['l1'], l2 = params['l2'])\n",
    "        ))\n",
    "        model.add(Dropout(params[f'dropout_{i+1}']))\n",
    "    # Output layer (binary classification)\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "    #compile the model\n",
    "    optimizer_name = params['optimizer']\n",
    "    learning_rate = params['learning_rate']\n",
    "\n",
    "    if optimizer_name == 'adam':\n",
    "        optimizer = Adam(learning_rate = learning_rate)\n",
    "    elif optimizer_name == 'sgd':\n",
    "        optimizer = SGD(learning_rate = learning_rate, momentum = params['momentum'])\n",
    "    else:\n",
    "        optimizer = RMSprop(learning_rate = learning_rate)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer = optimizer,\n",
    "        loss = 'binary_crossentropy',\n",
    "        metrics = ['accuracy', tf.keras.metrics.AUC(name = 'auc')]\n",
    "    )\n",
    "    return model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "636dc526-e87e-418a-b302-eae3d0a70ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object function for Optuna\n",
    "\n",
    "def objective(trial):\n",
    "    # Define hyperparametrs to tune\n",
    "    params = {\n",
    "        #network architecture\n",
    "        'n_layers': trial.suggest_int('n_layers', 1, 3),\n",
    "        'units_1': trial.suggest_int('units_1', 16, 256),\n",
    "        'units_2': trial.suggest_int('units_2', 16, 256),\n",
    "        'units_3': trial.suggest_int('units_3', 16, 256),\n",
    "        'units_4': trial.suggest_int('units_4', 16, 256),\n",
    "        'dropout_1': trial.suggest_float('dropout_1', 0.0, 0.5),\n",
    "        'dropout_2': trial.suggest_float('dropout_2', 0.0, 0.5),\n",
    "        'dropout_3': trial.suggest_float('dropout_3', 0.0, 0.5),\n",
    "        'dropout_4': trial.suggest_float('dropout_4', 0.0, 0.5),\n",
    "        'activation': trial.suggest_categorical('activation', ['relu', 'elu', 'selu']),\n",
    "\n",
    "        # Regularization\n",
    "        'l1': trial.suggest_float('l1', 1e-8, 1e-3, log = True),\n",
    "        'l2': trial.suggest_float('l2', 1e-8, 1e-3, log = True),\n",
    "\n",
    "        #Optimization\n",
    "        'optimizer': trial.suggest_categorical('optimizer', ['adam', 'sgd', 'rmsprop']),\n",
    "        'learnig_rate': trial.suggest_float('learning_rate', 1e-4, 1e-2, log = True),\n",
    "        'mometum': trial.suggest_float('momentum', 0.0, 0.99),\n",
    "        'batch_size': trial.suggest_categorical('batch_size', [16, 32, 64, 128]),\n",
    "        'epochs': 100, # Fixed number of maximum epochs with early stopping\n",
    "        \n",
    "    }\n",
    "\n",
    "\n",
    "    # use stratified k-fold cross-validation\n",
    "    n_folds = 5\n",
    "    skf = StratifiedKFold(n_splits = n_folds, shuffle = True, random_state = 42)\n",
    "    cv_scores = []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X_train_scaled, y_train):\n",
    "        X_fold_train, X_fold_val = X_train_scaled[train_idx], X_train_scaled[val_idx]\n",
    "        y_fold_train, y_fold_val = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "        # calculate class weights if imbalance\n",
    "        class_weights = compute_class_weight(\n",
    "            class_weight = 'balanced',\n",
    "            classes = np.unique(y_fold_train),\n",
    "            y = y_fold_train\n",
    "        )\n",
    "        class_weight_dict = {i: weight for i, weight in enumerated(class_weights)}\n",
    "\n",
    "        # Create and train model\n",
    "        model = create_model(params)\n",
    "\n",
    "        # Define callbacks\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor = 'val_auc',\n",
    "            patience = 10,\n",
    "            restore_best_weights = True,\n",
    "            mode = 'max'\n",
    "        )\n",
    "\n",
    "        reduce_lr = ReduceLROnPlateau(\n",
    "            monitor = 'val_loss',\n",
    "            factor = 0.2,\n",
    "            patience = 5, \n",
    "            min_lr = 1e-6\n",
    "        )\n",
    "\n",
    "        # Train the model\n",
    "        history = model.fit(\n",
    "            X_fold_train, y_fold_train,\n",
    "            epochs = params['epochs'],\n",
    "            batch_size = params['batch_size'],\n",
    "            validation_data = (X_fold_val, y_fold_val),\n",
    "            class_weight = calss_weight_dict,\n",
    "            callbacks = [early_stopping, reduce_lr],\n",
    "            verbose = 0\n",
    "        )\n",
    "\n",
    "        # Evaluate on validation set\n",
    "        y_pred_proba = model.predict(X_fold_val, verbose = 0)\n",
    "        y_preds = (y_pred_proba > 0.5).astype(int)\n",
    "\n",
    "        # Get AUC score\n",
    "        auc = roc_auc_score(y_fold_val, y_pred_proba)\n",
    "        cv_scores.append(auc)\n",
    "\n",
    "        # Free up score\n",
    "        tf.keras.backend.clear_session()\n",
    "        \n",
    "    # Return the mean AUC score across all fold\n",
    "    return np.mean(cv_scores)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265ec606-c2fd-4d5b-85bb-856658b7bba5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
